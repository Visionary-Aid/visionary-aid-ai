{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNknM2lqcZZWhQ+ZpQAT04t"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"73wq3Fa5w4Ri","executionInfo":{"status":"ok","timestamp":1746479178449,"user_tz":-180,"elapsed":332041,"user":{"displayName":"Ahmed Ashraf","userId":"16903420960414342842"}},"outputId":"868ea2b7-d6a6-4d2a-9cfa-166a05080ab7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n","100%|██████████| 20.5M/20.5M [00:00<00:00, 160MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1, Train Loss: 0.8512, Val Loss: 0.6553\n","Epoch 2, Train Loss: 0.4763, Val Loss: 0.5506\n","Epoch 3, Train Loss: 0.3128, Val Loss: 0.5328\n","Epoch 4, Train Loss: 0.2148, Val Loss: 0.5460\n","Epoch 5, Train Loss: 0.1589, Val Loss: 0.5832\n","✅ Model saved to Drive!\n"]}],"source":["# ================== 1. Setup ==================\n","!pip install pycocotools --quiet\n","import os, json, shutil, random\n","import torch\n","import torchvision\n","from torchvision import transforms\n","from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n","from torch.utils.data import Dataset, DataLoader\n","from PIL import Image\n","from sklearn.model_selection import train_test_split\n","from google.colab import drive\n","\n","drive.mount('/content/drive')\n","\n","# ================== 2. Download COCO val2017 ==================\n","!wget -q http://images.cocodataset.org/zips/val2017.zip\n","!unzip -q val2017.zip\n","!wget -q http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n","!unzip -q annotations_trainval2017.zip\n","\n","# ================== 3. Select Target Classes ==================\n","target_classes = ['person', 'car', 'dog', 'cat', 'bicycle']\n","coco_annotation_file = 'annotations/instances_val2017.json'\n","\n","with open(coco_annotation_file, 'r') as f:\n","    coco_data = json.load(f)\n","\n","category_id_to_name = {cat['id']: cat['name'] for cat in coco_data['categories']}\n","category_name_to_id = {v: k for k, v in category_id_to_name.items()}\n","target_class_ids = [category_name_to_id[c] for c in target_classes]\n","\n","# ================== 4. Collect Image -> Label ==================\n","image_id_to_label = {}\n","used_image_ids = set()\n","\n","for ann in coco_data['annotations']:\n","    if ann['category_id'] in target_class_ids:\n","        image_id = ann['image_id']\n","        if image_id not in image_id_to_label:  # 1 label per image\n","            image_id_to_label[image_id] = ann['category_id']\n","            used_image_ids.add(image_id)\n","\n","# ================== 5. Prepare Dataset ==================\n","save_dir = '/content/coco_classification'\n","images_dir = os.path.join(save_dir, 'images')\n","os.makedirs(images_dir, exist_ok=True)\n","\n","image_id_to_filename = {img['id']: img['file_name'] for img in coco_data['images']}\n","data = []\n","\n","for image_id, label_id in image_id_to_label.items():\n","    filename = image_id_to_filename[image_id]\n","    src = os.path.join('val2017', filename)\n","    dst = os.path.join(images_dir, filename)\n","    shutil.copyfile(src, dst)\n","    data.append((dst, target_class_ids.index(label_id)))  # class index: 0-4\n","\n","# ================== 6. Split Dataset ==================\n","train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n","\n","class COCODataset(Dataset):\n","    def __init__(self, data, transform=None):\n","        self.data = data\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        img_path, label = self.data[idx]\n","        image = Image.open(img_path).convert('RGB')\n","        if self.transform:\n","            image = self.transform(image)\n","        return image, label\n","\n","transform_train = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","])\n","\n","transform_val = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","])\n","\n","train_dataset = COCODataset(train_data, transform=transform_train)\n","val_dataset = COCODataset(val_data, transform=transform_val)\n","\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)\n","val_loader = DataLoader(val_dataset, batch_size=16, num_workers=2)\n","\n","# ================== 7. Model and Training ==================\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model = efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT)\n","model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, len(target_classes))\n","model = model.to(device)\n","\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","\n","from torch.amp import autocast, GradScaler\n","scaler = GradScaler()\n","\n","# ================== 8. Training Loop ==================\n","epochs = 5\n","for epoch in range(epochs):\n","    model.train()\n","    running_loss = 0.0\n","    for images, labels in train_loader:\n","        images, labels = images.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        with autocast(device_type='cuda'):\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","        running_loss += loss.item() * images.size(0)\n","    avg_train_loss = running_loss / len(train_dataset)\n","\n","    model.eval()\n","    val_loss = 0.0\n","    with torch.no_grad():\n","        for images, labels in val_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            with autocast(device_type='cuda'):\n","                outputs = model(images)\n","                loss = criterion(outputs, labels)\n","            val_loss += loss.item() * images.size(0)\n","    avg_val_loss = val_loss / len(val_dataset)\n","    print(f\"Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n","\n","# ================== 9. Save Model ==================\n","torch.save(model.state_dict(), '/content/drive/MyDrive/efficientnet_b0_coco5.pth')\n","print(\"✅ Model saved to Drive!\")\n"]}]}